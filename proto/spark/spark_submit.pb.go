// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        v5.29.3
// source: proto/spark_submit.proto

package spark

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Metadata for Kubernetes objects
type ObjectMeta struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Name          string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Namespace     string                 `protobuf:"bytes,2,opt,name=namespace,proto3" json:"namespace,omitempty"`
	Labels        map[string]string      `protobuf:"bytes,3,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	Annotations   map[string]string      `protobuf:"bytes,4,rep,name=annotations,proto3" json:"annotations,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ObjectMeta) Reset() {
	*x = ObjectMeta{}
	mi := &file_proto_spark_submit_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ObjectMeta) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ObjectMeta) ProtoMessage() {}

func (x *ObjectMeta) ProtoReflect() protoreflect.Message {
	mi := &file_proto_spark_submit_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ObjectMeta.ProtoReflect.Descriptor instead.
func (*ObjectMeta) Descriptor() ([]byte, []int) {
	return file_proto_spark_submit_proto_rawDescGZIP(), []int{0}
}

func (x *ObjectMeta) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ObjectMeta) GetNamespace() string {
	if x != nil {
		return x.Namespace
	}
	return ""
}

func (x *ObjectMeta) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *ObjectMeta) GetAnnotations() map[string]string {
	if x != nil {
		return x.Annotations
	}
	return nil
}

// SparkApplicationSpec
type SparkApplicationSpec struct {
	state               protoimpl.MessageState `protogen:"open.v1"`
	Type                string                 `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	Mode                string                 `protobuf:"bytes,2,opt,name=mode,proto3" json:"mode,omitempty"`
	Image               string                 `protobuf:"bytes,3,opt,name=image,proto3" json:"image,omitempty"`
	ImagePullPolicy     string                 `protobuf:"bytes,4,opt,name=image_pull_policy,json=imagePullPolicy,proto3" json:"image_pull_policy,omitempty"`
	SparkConf           map[string]string      `protobuf:"bytes,5,rep,name=spark_conf,json=sparkConf,proto3" json:"spark_conf,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	HadoopConf          map[string]string      `protobuf:"bytes,6,rep,name=hadoop_conf,json=hadoopConf,proto3" json:"hadoop_conf,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	SparkConfigMap      map[string]string      `protobuf:"bytes,7,rep,name=spark_config_map,json=sparkConfigMap,proto3" json:"spark_config_map,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	HadoopConfigMap     map[string]string      `protobuf:"bytes,8,rep,name=hadoop_config_map,json=hadoopConfigMap,proto3" json:"hadoop_config_map,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	Arguments           []string               `protobuf:"bytes,9,rep,name=arguments,proto3" json:"arguments,omitempty"`
	MainClass           string                 `protobuf:"bytes,10,opt,name=main_class,json=mainClass,proto3" json:"main_class,omitempty"`
	MainApplicationFile string                 `protobuf:"bytes,11,opt,name=main_application_file,json=mainApplicationFile,proto3" json:"main_application_file,omitempty"`
	PythonFiles         []string               `protobuf:"bytes,12,rep,name=python_files,json=pythonFiles,proto3" json:"python_files,omitempty"`
	Jars                []string               `protobuf:"bytes,13,rep,name=jars,proto3" json:"jars,omitempty"`
	Files               []string               `protobuf:"bytes,14,rep,name=files,proto3" json:"files,omitempty"`
	Archives            []string               `protobuf:"bytes,15,rep,name=archives,proto3" json:"archives,omitempty"`
	DriverCores         string                 `protobuf:"bytes,16,opt,name=driver_cores,json=driverCores,proto3" json:"driver_cores,omitempty"`
	DriverMemory        string                 `protobuf:"bytes,17,opt,name=driver_memory,json=driverMemory,proto3" json:"driver_memory,omitempty"`
	ExecutorCores       string                 `protobuf:"bytes,18,opt,name=executor_cores,json=executorCores,proto3" json:"executor_cores,omitempty"`
	ExecutorMemory      string                 `protobuf:"bytes,19,opt,name=executor_memory,json=executorMemory,proto3" json:"executor_memory,omitempty"`
	ExecutorInstances   int32                  `protobuf:"varint,20,opt,name=executor_instances,json=executorInstances,proto3" json:"executor_instances,omitempty"`
	Driver              *DriverSpec            `protobuf:"bytes,21,opt,name=driver,proto3" json:"driver,omitempty"`
	Executor            *ExecutorSpec          `protobuf:"bytes,22,opt,name=executor,proto3" json:"executor,omitempty"`
	Volumes             []*Volume              `protobuf:"bytes,23,rep,name=volumes,proto3" json:"volumes,omitempty"` // Add more fields as needed
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *SparkApplicationSpec) Reset() {
	*x = SparkApplicationSpec{}
	mi := &file_proto_spark_submit_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SparkApplicationSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SparkApplicationSpec) ProtoMessage() {}

func (x *SparkApplicationSpec) ProtoReflect() protoreflect.Message {
	mi := &file_proto_spark_submit_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SparkApplicationSpec.ProtoReflect.Descriptor instead.
func (*SparkApplicationSpec) Descriptor() ([]byte, []int) {
	return file_proto_spark_submit_proto_rawDescGZIP(), []int{1}
}

func (x *SparkApplicationSpec) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *SparkApplicationSpec) GetMode() string {
	if x != nil {
		return x.Mode
	}
	return ""
}

func (x *SparkApplicationSpec) GetImage() string {
	if x != nil {
		return x.Image
	}
	return ""
}

func (x *SparkApplicationSpec) GetImagePullPolicy() string {
	if x != nil {
		return x.ImagePullPolicy
	}
	return ""
}

func (x *SparkApplicationSpec) GetSparkConf() map[string]string {
	if x != nil {
		return x.SparkConf
	}
	return nil
}

func (x *SparkApplicationSpec) GetHadoopConf() map[string]string {
	if x != nil {
		return x.HadoopConf
	}
	return nil
}

func (x *SparkApplicationSpec) GetSparkConfigMap() map[string]string {
	if x != nil {
		return x.SparkConfigMap
	}
	return nil
}

func (x *SparkApplicationSpec) GetHadoopConfigMap() map[string]string {
	if x != nil {
		return x.HadoopConfigMap
	}
	return nil
}

func (x *SparkApplicationSpec) GetArguments() []string {
	if x != nil {
		return x.Arguments
	}
	return nil
}

func (x *SparkApplicationSpec) GetMainClass() string {
	if x != nil {
		return x.MainClass
	}
	return ""
}

func (x *SparkApplicationSpec) GetMainApplicationFile() string {
	if x != nil {
		return x.MainApplicationFile
	}
	return ""
}

func (x *SparkApplicationSpec) GetPythonFiles() []string {
	if x != nil {
		return x.PythonFiles
	}
	return nil
}

func (x *SparkApplicationSpec) GetJars() []string {
	if x != nil {
		return x.Jars
	}
	return nil
}

func (x *SparkApplicationSpec) GetFiles() []string {
	if x != nil {
		return x.Files
	}
	return nil
}

func (x *SparkApplicationSpec) GetArchives() []string {
	if x != nil {
		return x.Archives
	}
	return nil
}

func (x *SparkApplicationSpec) GetDriverCores() string {
	if x != nil {
		return x.DriverCores
	}
	return ""
}

func (x *SparkApplicationSpec) GetDriverMemory() string {
	if x != nil {
		return x.DriverMemory
	}
	return ""
}

func (x *SparkApplicationSpec) GetExecutorCores() string {
	if x != nil {
		return x.ExecutorCores
	}
	return ""
}

func (x *SparkApplicationSpec) GetExecutorMemory() string {
	if x != nil {
		return x.ExecutorMemory
	}
	return ""
}

func (x *SparkApplicationSpec) GetExecutorInstances() int32 {
	if x != nil {
		return x.ExecutorInstances
	}
	return 0
}

func (x *SparkApplicationSpec) GetDriver() *DriverSpec {
	if x != nil {
		return x.Driver
	}
	return nil
}

func (x *SparkApplicationSpec) GetExecutor() *ExecutorSpec {
	if x != nil {
		return x.Executor
	}
	return nil
}

func (x *SparkApplicationSpec) GetVolumes() []*Volume {
	if x != nil {
		return x.Volumes
	}
	return nil
}

// DriverSpec and ExecutorSpec
type DriverSpec struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Labels        map[string]string      `protobuf:"bytes,1,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	Env           map[string]string      `protobuf:"bytes,2,rep,name=env,proto3" json:"env,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	VolumeMounts  []*VolumeMount         `protobuf:"bytes,3,rep,name=volume_mounts,json=volumeMounts,proto3" json:"volume_mounts,omitempty"` // Add more fields as needed
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DriverSpec) Reset() {
	*x = DriverSpec{}
	mi := &file_proto_spark_submit_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DriverSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DriverSpec) ProtoMessage() {}

func (x *DriverSpec) ProtoReflect() protoreflect.Message {
	mi := &file_proto_spark_submit_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DriverSpec.ProtoReflect.Descriptor instead.
func (*DriverSpec) Descriptor() ([]byte, []int) {
	return file_proto_spark_submit_proto_rawDescGZIP(), []int{2}
}

func (x *DriverSpec) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *DriverSpec) GetEnv() map[string]string {
	if x != nil {
		return x.Env
	}
	return nil
}

func (x *DriverSpec) GetVolumeMounts() []*VolumeMount {
	if x != nil {
		return x.VolumeMounts
	}
	return nil
}

type ExecutorSpec struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Labels        map[string]string      `protobuf:"bytes,1,rep,name=labels,proto3" json:"labels,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	Env           map[string]string      `protobuf:"bytes,2,rep,name=env,proto3" json:"env,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	VolumeMounts  []*VolumeMount         `protobuf:"bytes,3,rep,name=volume_mounts,json=volumeMounts,proto3" json:"volume_mounts,omitempty"` // Add more fields as needed
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ExecutorSpec) Reset() {
	*x = ExecutorSpec{}
	mi := &file_proto_spark_submit_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ExecutorSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ExecutorSpec) ProtoMessage() {}

func (x *ExecutorSpec) ProtoReflect() protoreflect.Message {
	mi := &file_proto_spark_submit_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ExecutorSpec.ProtoReflect.Descriptor instead.
func (*ExecutorSpec) Descriptor() ([]byte, []int) {
	return file_proto_spark_submit_proto_rawDescGZIP(), []int{3}
}

func (x *ExecutorSpec) GetLabels() map[string]string {
	if x != nil {
		return x.Labels
	}
	return nil
}

func (x *ExecutorSpec) GetEnv() map[string]string {
	if x != nil {
		return x.Env
	}
	return nil
}

func (x *ExecutorSpec) GetVolumeMounts() []*VolumeMount {
	if x != nil {
		return x.VolumeMounts
	}
	return nil
}

// Volume and VolumeMount
type Volume struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Name          string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Type          string                 `protobuf:"bytes,2,opt,name=type,proto3" json:"type,omitempty"` // e.g., "hostPath", "emptyDir", etc.
	Path          string                 `protobuf:"bytes,3,opt,name=path,proto3" json:"path,omitempty"` // Add more fields as needed for different volume types
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Volume) Reset() {
	*x = Volume{}
	mi := &file_proto_spark_submit_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Volume) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Volume) ProtoMessage() {}

func (x *Volume) ProtoReflect() protoreflect.Message {
	mi := &file_proto_spark_submit_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Volume.ProtoReflect.Descriptor instead.
func (*Volume) Descriptor() ([]byte, []int) {
	return file_proto_spark_submit_proto_rawDescGZIP(), []int{4}
}

func (x *Volume) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Volume) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *Volume) GetPath() string {
	if x != nil {
		return x.Path
	}
	return ""
}

type VolumeMount struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Name          string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	MountPath     string                 `protobuf:"bytes,2,opt,name=mount_path,json=mountPath,proto3" json:"mount_path,omitempty"`
	ReadOnly      bool                   `protobuf:"varint,3,opt,name=read_only,json=readOnly,proto3" json:"read_only,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *VolumeMount) Reset() {
	*x = VolumeMount{}
	mi := &file_proto_spark_submit_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *VolumeMount) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*VolumeMount) ProtoMessage() {}

func (x *VolumeMount) ProtoReflect() protoreflect.Message {
	mi := &file_proto_spark_submit_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use VolumeMount.ProtoReflect.Descriptor instead.
func (*VolumeMount) Descriptor() ([]byte, []int) {
	return file_proto_spark_submit_proto_rawDescGZIP(), []int{5}
}

func (x *VolumeMount) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *VolumeMount) GetMountPath() string {
	if x != nil {
		return x.MountPath
	}
	return ""
}

func (x *VolumeMount) GetReadOnly() bool {
	if x != nil {
		return x.ReadOnly
	}
	return false
}

// SparkApplicationStatus (simplified)
type SparkApplicationStatus struct {
	state              protoimpl.MessageState `protogen:"open.v1"`
	ApplicationState   string                 `protobuf:"bytes,1,opt,name=application_state,json=applicationState,proto3" json:"application_state,omitempty"`
	SparkApplicationId string                 `protobuf:"bytes,2,opt,name=spark_application_id,json=sparkApplicationId,proto3" json:"spark_application_id,omitempty"`
	SubmissionId       string                 `protobuf:"bytes,3,opt,name=submission_id,json=submissionId,proto3" json:"submission_id,omitempty"` // Add more fields as needed
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *SparkApplicationStatus) Reset() {
	*x = SparkApplicationStatus{}
	mi := &file_proto_spark_submit_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SparkApplicationStatus) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SparkApplicationStatus) ProtoMessage() {}

func (x *SparkApplicationStatus) ProtoReflect() protoreflect.Message {
	mi := &file_proto_spark_submit_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SparkApplicationStatus.ProtoReflect.Descriptor instead.
func (*SparkApplicationStatus) Descriptor() ([]byte, []int) {
	return file_proto_spark_submit_proto_rawDescGZIP(), []int{6}
}

func (x *SparkApplicationStatus) GetApplicationState() string {
	if x != nil {
		return x.ApplicationState
	}
	return ""
}

func (x *SparkApplicationStatus) GetSparkApplicationId() string {
	if x != nil {
		return x.SparkApplicationId
	}
	return ""
}

func (x *SparkApplicationStatus) GetSubmissionId() string {
	if x != nil {
		return x.SubmissionId
	}
	return ""
}

// The SparkApplication CRD
type SparkApplication struct {
	state         protoimpl.MessageState  `protogen:"open.v1"`
	Metadata      *ObjectMeta             `protobuf:"bytes,1,opt,name=metadata,proto3" json:"metadata,omitempty"`
	Spec          *SparkApplicationSpec   `protobuf:"bytes,2,opt,name=spec,proto3" json:"spec,omitempty"`
	Status        *SparkApplicationStatus `protobuf:"bytes,3,opt,name=status,proto3" json:"status,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SparkApplication) Reset() {
	*x = SparkApplication{}
	mi := &file_proto_spark_submit_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SparkApplication) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SparkApplication) ProtoMessage() {}

func (x *SparkApplication) ProtoReflect() protoreflect.Message {
	mi := &file_proto_spark_submit_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SparkApplication.ProtoReflect.Descriptor instead.
func (*SparkApplication) Descriptor() ([]byte, []int) {
	return file_proto_spark_submit_proto_rawDescGZIP(), []int{7}
}

func (x *SparkApplication) GetMetadata() *ObjectMeta {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *SparkApplication) GetSpec() *SparkApplicationSpec {
	if x != nil {
		return x.Spec
	}
	return nil
}

func (x *SparkApplication) GetStatus() *SparkApplicationStatus {
	if x != nil {
		return x.Status
	}
	return nil
}

// The request message containing the SparkApplication and submission ID.
type RunAltSparkSubmitRequest struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	SparkApplication *SparkApplication      `protobuf:"bytes,1,opt,name=spark_application,json=sparkApplication,proto3" json:"spark_application,omitempty"`
	SubmissionId     string                 `protobuf:"bytes,2,opt,name=submission_id,json=submissionId,proto3" json:"submission_id,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *RunAltSparkSubmitRequest) Reset() {
	*x = RunAltSparkSubmitRequest{}
	mi := &file_proto_spark_submit_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RunAltSparkSubmitRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RunAltSparkSubmitRequest) ProtoMessage() {}

func (x *RunAltSparkSubmitRequest) ProtoReflect() protoreflect.Message {
	mi := &file_proto_spark_submit_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RunAltSparkSubmitRequest.ProtoReflect.Descriptor instead.
func (*RunAltSparkSubmitRequest) Descriptor() ([]byte, []int) {
	return file_proto_spark_submit_proto_rawDescGZIP(), []int{8}
}

func (x *RunAltSparkSubmitRequest) GetSparkApplication() *SparkApplication {
	if x != nil {
		return x.SparkApplication
	}
	return nil
}

func (x *RunAltSparkSubmitRequest) GetSubmissionId() string {
	if x != nil {
		return x.SubmissionId
	}
	return ""
}

// The response message indicating success or failure.
type RunAltSparkSubmitResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Success       bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	ErrorMessage  string                 `protobuf:"bytes,2,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RunAltSparkSubmitResponse) Reset() {
	*x = RunAltSparkSubmitResponse{}
	mi := &file_proto_spark_submit_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RunAltSparkSubmitResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RunAltSparkSubmitResponse) ProtoMessage() {}

func (x *RunAltSparkSubmitResponse) ProtoReflect() protoreflect.Message {
	mi := &file_proto_spark_submit_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RunAltSparkSubmitResponse.ProtoReflect.Descriptor instead.
func (*RunAltSparkSubmitResponse) Descriptor() ([]byte, []int) {
	return file_proto_spark_submit_proto_rawDescGZIP(), []int{9}
}

func (x *RunAltSparkSubmitResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *RunAltSparkSubmitResponse) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

var File_proto_spark_submit_proto protoreflect.FileDescriptor

const file_proto_spark_submit_proto_rawDesc = "" +
	"\n" +
	"\x18proto/spark_submit.proto\x12\x05spark\"\xb6\x02\n" +
	"\n" +
	"ObjectMeta\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x1c\n" +
	"\tnamespace\x18\x02 \x01(\tR\tnamespace\x125\n" +
	"\x06labels\x18\x03 \x03(\v2\x1d.spark.ObjectMeta.LabelsEntryR\x06labels\x12D\n" +
	"\vannotations\x18\x04 \x03(\v2\".spark.ObjectMeta.AnnotationsEntryR\vannotations\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1a>\n" +
	"\x10AnnotationsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xfc\t\n" +
	"\x14SparkApplicationSpec\x12\x12\n" +
	"\x04type\x18\x01 \x01(\tR\x04type\x12\x12\n" +
	"\x04mode\x18\x02 \x01(\tR\x04mode\x12\x14\n" +
	"\x05image\x18\x03 \x01(\tR\x05image\x12*\n" +
	"\x11image_pull_policy\x18\x04 \x01(\tR\x0fimagePullPolicy\x12I\n" +
	"\n" +
	"spark_conf\x18\x05 \x03(\v2*.spark.SparkApplicationSpec.SparkConfEntryR\tsparkConf\x12L\n" +
	"\vhadoop_conf\x18\x06 \x03(\v2+.spark.SparkApplicationSpec.HadoopConfEntryR\n" +
	"hadoopConf\x12Y\n" +
	"\x10spark_config_map\x18\a \x03(\v2/.spark.SparkApplicationSpec.SparkConfigMapEntryR\x0esparkConfigMap\x12\\\n" +
	"\x11hadoop_config_map\x18\b \x03(\v20.spark.SparkApplicationSpec.HadoopConfigMapEntryR\x0fhadoopConfigMap\x12\x1c\n" +
	"\targuments\x18\t \x03(\tR\targuments\x12\x1d\n" +
	"\n" +
	"main_class\x18\n" +
	" \x01(\tR\tmainClass\x122\n" +
	"\x15main_application_file\x18\v \x01(\tR\x13mainApplicationFile\x12!\n" +
	"\fpython_files\x18\f \x03(\tR\vpythonFiles\x12\x12\n" +
	"\x04jars\x18\r \x03(\tR\x04jars\x12\x14\n" +
	"\x05files\x18\x0e \x03(\tR\x05files\x12\x1a\n" +
	"\barchives\x18\x0f \x03(\tR\barchives\x12!\n" +
	"\fdriver_cores\x18\x10 \x01(\tR\vdriverCores\x12#\n" +
	"\rdriver_memory\x18\x11 \x01(\tR\fdriverMemory\x12%\n" +
	"\x0eexecutor_cores\x18\x12 \x01(\tR\rexecutorCores\x12'\n" +
	"\x0fexecutor_memory\x18\x13 \x01(\tR\x0eexecutorMemory\x12-\n" +
	"\x12executor_instances\x18\x14 \x01(\x05R\x11executorInstances\x12)\n" +
	"\x06driver\x18\x15 \x01(\v2\x11.spark.DriverSpecR\x06driver\x12/\n" +
	"\bexecutor\x18\x16 \x01(\v2\x13.spark.ExecutorSpecR\bexecutor\x12'\n" +
	"\avolumes\x18\x17 \x03(\v2\r.spark.VolumeR\avolumes\x1a<\n" +
	"\x0eSparkConfEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1a=\n" +
	"\x0fHadoopConfEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1aA\n" +
	"\x13SparkConfigMapEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1aB\n" +
	"\x14HadoopConfigMapEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\x9d\x02\n" +
	"\n" +
	"DriverSpec\x125\n" +
	"\x06labels\x18\x01 \x03(\v2\x1d.spark.DriverSpec.LabelsEntryR\x06labels\x12,\n" +
	"\x03env\x18\x02 \x03(\v2\x1a.spark.DriverSpec.EnvEntryR\x03env\x127\n" +
	"\rvolume_mounts\x18\x03 \x03(\v2\x12.spark.VolumeMountR\fvolumeMounts\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1a6\n" +
	"\bEnvEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"\xa3\x02\n" +
	"\fExecutorSpec\x127\n" +
	"\x06labels\x18\x01 \x03(\v2\x1f.spark.ExecutorSpec.LabelsEntryR\x06labels\x12.\n" +
	"\x03env\x18\x02 \x03(\v2\x1c.spark.ExecutorSpec.EnvEntryR\x03env\x127\n" +
	"\rvolume_mounts\x18\x03 \x03(\v2\x12.spark.VolumeMountR\fvolumeMounts\x1a9\n" +
	"\vLabelsEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\x1a6\n" +
	"\bEnvEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"D\n" +
	"\x06Volume\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x12\n" +
	"\x04type\x18\x02 \x01(\tR\x04type\x12\x12\n" +
	"\x04path\x18\x03 \x01(\tR\x04path\"]\n" +
	"\vVolumeMount\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x1d\n" +
	"\n" +
	"mount_path\x18\x02 \x01(\tR\tmountPath\x12\x1b\n" +
	"\tread_only\x18\x03 \x01(\bR\breadOnly\"\x9c\x01\n" +
	"\x16SparkApplicationStatus\x12+\n" +
	"\x11application_state\x18\x01 \x01(\tR\x10applicationState\x120\n" +
	"\x14spark_application_id\x18\x02 \x01(\tR\x12sparkApplicationId\x12#\n" +
	"\rsubmission_id\x18\x03 \x01(\tR\fsubmissionId\"\xa9\x01\n" +
	"\x10SparkApplication\x12-\n" +
	"\bmetadata\x18\x01 \x01(\v2\x11.spark.ObjectMetaR\bmetadata\x12/\n" +
	"\x04spec\x18\x02 \x01(\v2\x1b.spark.SparkApplicationSpecR\x04spec\x125\n" +
	"\x06status\x18\x03 \x01(\v2\x1d.spark.SparkApplicationStatusR\x06status\"\x85\x01\n" +
	"\x18RunAltSparkSubmitRequest\x12D\n" +
	"\x11spark_application\x18\x01 \x01(\v2\x17.spark.SparkApplicationR\x10sparkApplication\x12#\n" +
	"\rsubmission_id\x18\x02 \x01(\tR\fsubmissionId\"Z\n" +
	"\x19RunAltSparkSubmitResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12#\n" +
	"\rerror_message\x18\x02 \x01(\tR\ferrorMessage2l\n" +
	"\x12SparkSubmitService\x12V\n" +
	"\x11RunAltSparkSubmit\x12\x1f.spark.RunAltSparkSubmitRequest\x1a .spark.RunAltSparkSubmitResponseB\x1aZ\x18nativesubmit/proto/sparkb\x06proto3"

var (
	file_proto_spark_submit_proto_rawDescOnce sync.Once
	file_proto_spark_submit_proto_rawDescData []byte
)

func file_proto_spark_submit_proto_rawDescGZIP() []byte {
	file_proto_spark_submit_proto_rawDescOnce.Do(func() {
		file_proto_spark_submit_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_proto_spark_submit_proto_rawDesc), len(file_proto_spark_submit_proto_rawDesc)))
	})
	return file_proto_spark_submit_proto_rawDescData
}

var file_proto_spark_submit_proto_msgTypes = make([]protoimpl.MessageInfo, 20)
var file_proto_spark_submit_proto_goTypes = []any{
	(*ObjectMeta)(nil),                // 0: spark.ObjectMeta
	(*SparkApplicationSpec)(nil),      // 1: spark.SparkApplicationSpec
	(*DriverSpec)(nil),                // 2: spark.DriverSpec
	(*ExecutorSpec)(nil),              // 3: spark.ExecutorSpec
	(*Volume)(nil),                    // 4: spark.Volume
	(*VolumeMount)(nil),               // 5: spark.VolumeMount
	(*SparkApplicationStatus)(nil),    // 6: spark.SparkApplicationStatus
	(*SparkApplication)(nil),          // 7: spark.SparkApplication
	(*RunAltSparkSubmitRequest)(nil),  // 8: spark.RunAltSparkSubmitRequest
	(*RunAltSparkSubmitResponse)(nil), // 9: spark.RunAltSparkSubmitResponse
	nil,                               // 10: spark.ObjectMeta.LabelsEntry
	nil,                               // 11: spark.ObjectMeta.AnnotationsEntry
	nil,                               // 12: spark.SparkApplicationSpec.SparkConfEntry
	nil,                               // 13: spark.SparkApplicationSpec.HadoopConfEntry
	nil,                               // 14: spark.SparkApplicationSpec.SparkConfigMapEntry
	nil,                               // 15: spark.SparkApplicationSpec.HadoopConfigMapEntry
	nil,                               // 16: spark.DriverSpec.LabelsEntry
	nil,                               // 17: spark.DriverSpec.EnvEntry
	nil,                               // 18: spark.ExecutorSpec.LabelsEntry
	nil,                               // 19: spark.ExecutorSpec.EnvEntry
}
var file_proto_spark_submit_proto_depIdxs = []int32{
	10, // 0: spark.ObjectMeta.labels:type_name -> spark.ObjectMeta.LabelsEntry
	11, // 1: spark.ObjectMeta.annotations:type_name -> spark.ObjectMeta.AnnotationsEntry
	12, // 2: spark.SparkApplicationSpec.spark_conf:type_name -> spark.SparkApplicationSpec.SparkConfEntry
	13, // 3: spark.SparkApplicationSpec.hadoop_conf:type_name -> spark.SparkApplicationSpec.HadoopConfEntry
	14, // 4: spark.SparkApplicationSpec.spark_config_map:type_name -> spark.SparkApplicationSpec.SparkConfigMapEntry
	15, // 5: spark.SparkApplicationSpec.hadoop_config_map:type_name -> spark.SparkApplicationSpec.HadoopConfigMapEntry
	2,  // 6: spark.SparkApplicationSpec.driver:type_name -> spark.DriverSpec
	3,  // 7: spark.SparkApplicationSpec.executor:type_name -> spark.ExecutorSpec
	4,  // 8: spark.SparkApplicationSpec.volumes:type_name -> spark.Volume
	16, // 9: spark.DriverSpec.labels:type_name -> spark.DriverSpec.LabelsEntry
	17, // 10: spark.DriverSpec.env:type_name -> spark.DriverSpec.EnvEntry
	5,  // 11: spark.DriverSpec.volume_mounts:type_name -> spark.VolumeMount
	18, // 12: spark.ExecutorSpec.labels:type_name -> spark.ExecutorSpec.LabelsEntry
	19, // 13: spark.ExecutorSpec.env:type_name -> spark.ExecutorSpec.EnvEntry
	5,  // 14: spark.ExecutorSpec.volume_mounts:type_name -> spark.VolumeMount
	0,  // 15: spark.SparkApplication.metadata:type_name -> spark.ObjectMeta
	1,  // 16: spark.SparkApplication.spec:type_name -> spark.SparkApplicationSpec
	6,  // 17: spark.SparkApplication.status:type_name -> spark.SparkApplicationStatus
	7,  // 18: spark.RunAltSparkSubmitRequest.spark_application:type_name -> spark.SparkApplication
	8,  // 19: spark.SparkSubmitService.RunAltSparkSubmit:input_type -> spark.RunAltSparkSubmitRequest
	9,  // 20: spark.SparkSubmitService.RunAltSparkSubmit:output_type -> spark.RunAltSparkSubmitResponse
	20, // [20:21] is the sub-list for method output_type
	19, // [19:20] is the sub-list for method input_type
	19, // [19:19] is the sub-list for extension type_name
	19, // [19:19] is the sub-list for extension extendee
	0,  // [0:19] is the sub-list for field type_name
}

func init() { file_proto_spark_submit_proto_init() }
func file_proto_spark_submit_proto_init() {
	if File_proto_spark_submit_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_proto_spark_submit_proto_rawDesc), len(file_proto_spark_submit_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   20,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_proto_spark_submit_proto_goTypes,
		DependencyIndexes: file_proto_spark_submit_proto_depIdxs,
		MessageInfos:      file_proto_spark_submit_proto_msgTypes,
	}.Build()
	File_proto_spark_submit_proto = out.File
	file_proto_spark_submit_proto_goTypes = nil
	file_proto_spark_submit_proto_depIdxs = nil
}
